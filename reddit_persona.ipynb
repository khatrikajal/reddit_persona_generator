{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkTSmj1TogvT",
        "outputId": "1e4bf4af-2aad-43d2-ee07-c09b02298a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.9)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Paste Reddit URL (user / subreddit / post): https://www.reddit.com/user/spez/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "1it [00:01,  1.53s/it]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "2it [00:03,  2.06s/it]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "3it [00:07,  2.71s/it]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "4it [00:11,  3.08s/it]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "5it [00:13,  2.71s/it]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "6it [00:17,  3.18s/it]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "7it [00:20,  3.12s/it]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "8it [00:21,  2.64s/it]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "9it [00:24,  2.55s/it]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "10it [00:25,  2.53s/it]\n",
            "0it [00:00, ?it/s]WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "10it [00:00, 32.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to scraped_reddit_data.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import re\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "REDDIT_CLIENT_ID = os.getenv(\"REDDIT_CLIENT_ID\")\n",
        "REDDIT_CLIENT_SECRET = os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
        "REDDIT_USER_AGENT = os.getenv(\"REDDIT_USER_AGENT\")\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=REDDIT_CLIENT_ID,\n",
        "    client_secret=REDDIT_CLIENT_SECRET,\n",
        "    user_agent=REDDIT_USER_AGENT\n",
        ")\n",
        "\n",
        "def is_image(url):\n",
        "    return any(url.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif'])\n",
        "\n",
        "def download_image(url, save_dir='images'):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    filename = os.path.join(save_dir, url.split(\"/\")[-1])\n",
        "    try:\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(filename, 'wb') as f:\n",
        "            for chunk in r.iter_content(1024):\n",
        "                f.write(chunk)\n",
        "        return filename\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def extract_post_data(post, data_type):\n",
        "    return {\n",
        "        'type': data_type,\n",
        "        'title': getattr(post, 'title', ''),\n",
        "        'body': getattr(post, 'body', ''),\n",
        "        'score': post.score,\n",
        "        'url': post.url,\n",
        "        'selftext': getattr(post, 'selftext', ''),\n",
        "        'subreddit': str(post.subreddit),\n",
        "        'image_path': download_image(post.url) if is_image(post.url) else None\n",
        "    }\n",
        "\n",
        "def scrape_subreddit(subreddit_name, limit=10):\n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "    data = []\n",
        "    for post in tqdm(subreddit.hot(limit=limit)):\n",
        "        item = extract_post_data(post, 'subreddit_post')\n",
        "        post.comments.replace_more(limit=0)\n",
        "        item['comments'] = [comment.body for comment in post.comments.list()]\n",
        "        item['author'] = str(post.author)\n",
        "        item['num_comments'] = post.num_comments\n",
        "        data.append(item)\n",
        "    return data, None\n",
        "\n",
        "def scrape_user(username, limit=10):\n",
        "    user = reddit.redditor(username)\n",
        "    data = []\n",
        "    for post in tqdm(user.submissions.new(limit=limit)):\n",
        "        item = extract_post_data(post, 'user_post')\n",
        "        item['username'] = username\n",
        "        data.append(item)\n",
        "    for comment in tqdm(user.comments.new(limit=limit)):\n",
        "        item = {\n",
        "            'type': 'user_comment',\n",
        "            'body': comment.body,\n",
        "            'score': comment.score,\n",
        "            'link_title': comment.link_title,\n",
        "            'subreddit': str(comment.subreddit),\n",
        "            'username': username\n",
        "        }\n",
        "        data.append(item)\n",
        "    return data, username\n",
        "\n",
        "def scrape_post(post_url):\n",
        "    submission = reddit.submission(url=post_url)\n",
        "    submission.comments.replace_more(limit=0)\n",
        "    comments = [comment.body for comment in submission.comments.list()]\n",
        "    return {\n",
        "        'type': 'post',\n",
        "        'title': submission.title,\n",
        "        'author': str(submission.author),\n",
        "        'selftext': submission.selftext,\n",
        "        'url': submission.url,\n",
        "        'score': submission.score,\n",
        "        'subreddit': str(submission.subreddit),\n",
        "        'image_path': download_image(submission.url) if is_image(submission.url) else None,\n",
        "        'comments': comments\n",
        "    }, None\n",
        "\n",
        "def scrape_reddit_from_url(url):\n",
        "    if re.match(r'https?://(www\\.)?reddit\\.com/r/[^/]+/?$', url):\n",
        "        sub_name = url.split('/r/')[1].strip('/')\n",
        "        return scrape_subreddit(sub_name, limit=10)\n",
        "    elif re.match(r'https?://(www\\.)?reddit\\.com/user/[^/]+/?$', url) or re.match(r'https?://(www\\.)?reddit\\.com/user/[^/]+/comments/?$', url):\n",
        "        username = url.split('/user/')[1].strip('/')\n",
        "        return scrape_user(username, limit=10)\n",
        "    elif re.match(r'https?://(www\\.)?reddit\\.com/r/.+/comments/.+/?$', url):\n",
        "        post, _ = scrape_post(url)\n",
        "        return [post], None\n",
        "    else:\n",
        "        print(\"Unsupported URL format\")\n",
        "        return [], None\n",
        "\n",
        "reddit_url = input(\"Paste Reddit URL (user / subreddit / post): \").strip()\n",
        "scraped_data, extracted_username = scrape_reddit_from_url(reddit_url)\n",
        "df = pd.json_normalize(scraped_data)\n",
        "df.to_csv(\"scraped_reddit_data.csv\", index=False)\n",
        "print(\"Data saved to scraped_reddit_data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QM1knd2dvVj",
        "outputId": "7b1f01cc-813c-4805-80ee-b6c07eae450b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Persona card saved as persona_card.png\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "import textwrap\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os\n",
        "\n",
        "CSV_PATH = \"D:\\reddit_persona_generator\\scraped_reddit_data.csv\"\n",
        "\n",
        "MODEL = \"mistralai/mistral-7b-instruct:free\"\n",
        "\n",
        "load_dotenv()\n",
        "API_KEY = os.getenv(\"API_KEY\")\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "def extract_username(df):\n",
        "    for col in ['author', 'username']:\n",
        "        if col in df.columns and df[col].dropna().nunique() == 1:\n",
        "            return df[col].dropna().unique()[0]\n",
        "    return \"Redditor\"\n",
        "\n",
        "def prepare_prompt(df, forced_username=None):\n",
        "    titles = next((df[col].dropna().tolist() for col in ['title', 'post_title'] if col in df.columns), [])\n",
        "    comments = next((df[col].dropna().tolist() for col in ['body', 'selftext', 'comment_body', 'text', 'content'] if col in df.columns), [])\n",
        "    subreddits = df['subreddit'].dropna().unique().tolist() if 'subreddit' in df.columns else []\n",
        "    avg_score = int(df['score'].mean()) if 'score' in df.columns else 0\n",
        "    username = forced_username if forced_username else extract_username(df)\n",
        "    sample_activity = \"\\n\".join([f\"Title: {t}\" for t in titles[:5]] + [f\"Comment: {c}\" for c in comments[:5]])\n",
        "    subreddit_str = \", \".join(subreddits[:5])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a senior user researcher and behavioral analyst working for a UX team. Based on a Reddit user's recent activity, generate a detailed persona.\n",
        "\n",
        "### USER DATA\n",
        "- Reddit Username: {username}\n",
        "- Subreddits Participated: {subreddit_str}\n",
        "- Average Upvote Score: {avg_score}\n",
        "- Sample Activity:\n",
        "{sample_activity}\n",
        "\n",
        "### TASK\n",
        "Generate a realistic persona including:\n",
        "\n",
        "{{\n",
        "  \"name\": \"{username}\",\n",
        "  \"age\": \"Estimated Age or Unknown\",\n",
        "  \"location\": \"Location or Unknown\",\n",
        "  \"motivations\": [\"...\"],\n",
        "  \"frustrations\": [\"...\"],\n",
        "  \"goals\": [\"...\"],\n",
        "  \"interests\": [\"...\"],\n",
        "  \"personality\": {{\n",
        "    \"Introvert\": 70,\n",
        "    \"Intuitive\": 65,\n",
        "    \"Thinking\": 85,\n",
        "    \"Perceiving\": 60\n",
        "  }},\n",
        "  \"tone\": \"...\",\n",
        "  \"behavior\": \"...\"\n",
        "}}\n",
        "Only return valid JSON.\n",
        "\"\"\"\n",
        "    return prompt, username\n",
        "\n",
        "def call_mistral(prompt):\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": MODEL,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "        match = re.search(r'\\{[\\s\\S]+\\}', content)\n",
        "        if match:\n",
        "            return json.loads(match.group(0))\n",
        "        raise ValueError(\"Could not parse JSON.\")\n",
        "    else:\n",
        "        raise Exception(f\"API Error: {response.status_code}\\n{response.text}\")\n",
        "\n",
        "def draw_full_persona_card(persona, username, filename=\"persona_card.png\"):\n",
        "    W, H = 1600, 1200\n",
        "    img = Image.new(\"RGB\", (W, H), \"white\")\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    FONT_DIR = \"fonts\"\n",
        "    try:\n",
        "        title_font = ImageFont.truetype(f\"{FONT_DIR}/Poppins-Bold.ttf\", 40)\n",
        "        section_font = ImageFont.truetype(f\"{FONT_DIR}/Poppins-Bold.ttf\", 28)\n",
        "        text_font = ImageFont.truetype(f\"{FONT_DIR}/Poppins-Regular.ttf\", 18)\n",
        "        small_font = ImageFont.truetype(f\"{FONT_DIR}/Poppins-Regular.ttf\", 15)\n",
        "    except:\n",
        "        title_font = ImageFont.load_default()\n",
        "        section_font = title_font\n",
        "        text_font = title_font\n",
        "        small_font = title_font\n",
        "\n",
        "    spacing = 35\n",
        "    draw.ellipse((80, 80, 380, 380), fill=\"#f2f2f2\", outline=\"#ccc\")\n",
        "\n",
        "    name = persona.get(\"name\", username)\n",
        "    age = str(persona.get(\"age\", \"Unknown\"))\n",
        "    location = persona.get(\"location\", \"Unknown\")\n",
        "\n",
        "    draw.text((420, 100), name, font=title_font, fill=\"#ec6608\")\n",
        "    draw.text((420, 170), \"AGE\", font=section_font, fill=\"#ec6608\")\n",
        "    draw.text((520, 170), age, font=text_font, fill=\"black\")\n",
        "    draw.text((420, 220), \"LOCATION\", font=section_font, fill=\"#ec6608\")\n",
        "    draw.text((580, 220), location, font=text_font, fill=\"black\")\n",
        "\n",
        "    y_start = 400\n",
        "    x_left = 80\n",
        "    x_right = 850\n",
        "\n",
        "\n",
        "    def draw_section(title, lines, x, y):\n",
        "        draw.text((x, y), title.upper(), font=section_font, fill=\"#ec6608\")\n",
        "        y += spacing\n",
        "        wrapper = textwrap.TextWrapper(width=50)\n",
        "        for item in lines:\n",
        "            for line in wrapper.wrap(item):\n",
        "                draw.text((x, y), f\"- {line}\", font=text_font, fill=\"black\")\n",
        "                y += spacing\n",
        "        return y + spacing // 2\n",
        "\n",
        "    def draw_personality(p, x, y):\n",
        "        draw.text((x, y), \"PERSONALITY\", font=section_font, fill=\"#ec6608\")\n",
        "        y += spacing\n",
        "        for trait, value in p.items():\n",
        "            draw.text((x, y), trait.upper(), font=small_font, fill=\"black\")\n",
        "            bx, by = x + 160, y + 8\n",
        "            bw = 300\n",
        "            val = int(value) if isinstance(value, int) else 50\n",
        "            draw.rectangle([bx, by, bx + bw, by + 15], fill=\"#ddd\")\n",
        "            draw.rectangle([bx, by, bx + int(bw * val / 100), by + 15], fill=\"#ec6608\")\n",
        "            y += spacing\n",
        "        return y + spacing // 2\n",
        "\n",
        "    y_left = y_start\n",
        "    y_left = draw_section(\"Motivations\", persona.get(\"motivations\", []), x_left, y_left)\n",
        "    y_left = draw_section(\"Frustrations\", persona.get(\"frustrations\", []), x_left, y_left)\n",
        "    y_left = draw_section(\"Goals\", persona.get(\"goals\", []), x_left, y_left)\n",
        "    y_left = draw_section(\"Interests\", persona.get(\"interests\", []), x_left, y_left)\n",
        "\n",
        "    y_right = y_start\n",
        "    y_right = draw_personality(persona.get(\"personality\", {}), x_right, y_right)\n",
        "    y_right = draw_section(\"Tone\", [persona.get(\"tone\", \"\")], x_right, y_right)\n",
        "    y_right = draw_section(\"Behaviour\", [persona.get(\"behavior\", \"\")], x_right, y_right)\n",
        "\n",
        "    img.save(filename)\n",
        "    print(f\"Persona card saved as {filename}\")\n",
        "\n",
        "prompt, username = prepare_prompt(df)\n",
        "persona = call_mistral(prompt)\n",
        "draw_full_persona_card(persona, username)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwnonNY6mNxD",
        "outputId": "679a39ab-d0e5-4c62-d1fe-e8976336432c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Persona text saved as spez_persona.txt\n"
          ]
        }
      ],
      "source": [
        "with open(f\"{username}_persona.txt\", \"w\") as f:\n",
        "    json.dump(persona, f, indent=2)\n",
        "print(f\"Persona text saved as {username}_persona.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8pzc__4t1vs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
